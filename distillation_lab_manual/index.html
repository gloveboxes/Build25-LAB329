
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../media/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>Model Distillation Lab Manual: Teaching Small Models to Be Smart - Build your code-first agent with Azure AI Foundry</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../css/custom.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
   <link href="../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="pink">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#model-distillation-lab-manual-teaching-small-models-to-be-smart" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Build your code-first agent with Azure AI Foundry" class="md-header__button md-logo" aria-label="Build your code-first agent with Azure AI Foundry" data-md-component="logo">
      
  <img src="../media/favicon.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Build your code-first agent with Azure AI Foundry
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Model Distillation Lab Manual: Teaching Small Models to Be Smart
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="pink"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 2c-1.82 0-3.53.5-5 1.35C8 5.08 10 8.3 10 12s-2 6.92-5 8.65C6.47 21.5 8.18 22 10 22a10 10 0 0 0 10-10A10 10 0 0 0 10 2"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="amber" data-md-color-accent="cyan"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
    
  </nav>
  
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Build your code-first agent with Azure AI Foundry" class="md-nav__button md-logo" aria-label="Build your code-first agent with Azure AI Foundry" data-md-component="logo">
      
  <img src="../media/favicon.png" alt="logo">

    </a>
    Build your code-first agent with Azure AI Foundry
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Model Distillation Lab Manual | Teaching Small Models to Be Smart
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Skillable_lab_manual1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Step 1 Generate Training Data
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Skillable_lab_manual2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Step 2 Fine-tune and Optimize
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Skillable_lab_manual3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Step 3 Test Your ONNX Model
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Skillable_lab_manual4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Step 4 Register to Azure ML
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Skillable_lab_manual5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Step 5 Download the Model
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Skillable_lab_manual6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Step 6 Local Inference
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Skillable_lab_manual7/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Step 7 Local Inference with Foundry Local
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Skillable_lab_manualconclusion/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Conclusion
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#workshop-duration-and-timing" class="md-nav__link">
    <span class="md-ellipsis">
      Workshop Duration and Timing
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#table-of-contents" class="md-nav__link">
    <span class="md-ellipsis">
      Table of Contents
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#workshop-overview" class="md-nav__link">
    <span class="md-ellipsis">
      Workshop Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prerequisites-check" class="md-nav__link">
    <span class="md-ellipsis">
      Prerequisites Check
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#environment-setup" class="md-nav__link">
    <span class="md-ellipsis">
      Environment Setup
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notebook-by-notebook-guide" class="md-nav__link">
    <span class="md-ellipsis">
      Notebook-by-Notebook Guide
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#clone-the-github-repo-and-resources-to-your-azure-ml-studio" class="md-nav__link">
    <span class="md-ellipsis">
      Clone the GitHub Repo and resources to your Azure ML Studio
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#step-1-generate-training-data-15-min" class="md-nav__link">
    <span class="md-ellipsis">
      Step 1: Generate Training Data (15 min)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#troubleshooting-guide" class="md-nav__link">
    <span class="md-ellipsis">
      Troubleshooting Guide
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#what-youve-learned" class="md-nav__link">
    <span class="md-ellipsis">
      What You've Learned
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      Next Steps
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="model-distillation-lab-manual-teaching-small-models-to-be-smart">Model Distillation Lab Manual: Teaching Small Models to Be Smart<a class="headerlink" href="#model-distillation-lab-manual-teaching-small-models-to-be-smart" title="Permanent link">&para;</a></h1>
<h2 id="workshop-duration-and-timing">Workshop Duration and Timing<a class="headerlink" href="#workshop-duration-and-timing" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>Total Workshop Time</strong>: 70 minutes</li>
<li><strong>Setup Time</strong>: 5 minutes</li>
<li><strong>Hands-On Activities</strong>: 60 minutes</li>
<li><strong>Discussion Time</strong>: 5 minutes</li>
</ul>
<h2 id="table-of-contents">Table of Contents<a class="headerlink" href="#table-of-contents" title="Permanent link">&para;</a></h2>
<ul>
<li><a href="#workshop-overview">Workshop Overview</a></li>
<li><a href="#prerequisites-check">Prerequisites Check</a></li>
<li><a href="#environment-setup">Environment Setup</a></li>
<li><a href="#notebook-by-notebook-guide">Notebook-by-Notebook Guide</a></li>
<li><a href="#step-1-generate-training-data-15-min">Step 1: Generate Training Data (15 min)</a></li>
<li><a href="#step-2-fine-tune-and-optimize-15-min">Step 2: Fine-tune and Optimize (15 min)</a></li>
<li><a href="#step-3-test-your-onnx-model-10-min">Step 3: Test Your ONNX Model (10 min)</a></li>
<li><a href="#step-4-register-to-azure-ml-5-min">Step 4: Register to Azure ML (5 min)</a></li>
<li><a href="#step-5-download-the-model-5-min">Step 5: Download the Model (5 min)</a></li>
<li><a href="#step-6-local-inference-10-min">Step 6: Local Inference (10 min)</a></li>
<li><a href="#troubleshooting-guide">Troubleshooting Guide</a></li>
<li><a href="#what-youve-learned">What You've Learned</a></li>
<li><a href="#next-steps">Next Steps</a></li>
</ul>
<h2 id="workshop-overview">Workshop Overview<a class="headerlink" href="#workshop-overview" title="Permanent link">&para;</a></h2>
<p>Welcome to the Model Distillation Workshop! In this hands-on session, you'll learn how to transform a large language model (DeepSeek-V3) into a smaller, equally capable model (Phi-4-mini) using knowledge distillation.</p>
<h3 id="what-youll-build">What You'll Build<a class="headerlink" href="#what-youll-build" title="Permanent link">&para;</a></h3>
<p>By the end of this workshop, you'll create a compact language model that:
- Is <strong>75% smaller</strong> than the original teacher model
- Runs on <strong>standard hardware</strong> without specialized GPUs
- Can be deployed on <strong>edge devices</strong> or embedded systems
- Maintains most of the <strong>capabilities</strong> of the larger model</p>
<h3 id="workshop-flow">Workshop Flow<a class="headerlink" href="#workshop-flow" title="Permanent link">&para;</a></h3>
<p>This is a <strong>practical, code-first workshop</strong>. You'll work through six Jupyter notebooks that guide you step-by-step through:</p>
<ol>
<li><strong>Data Generation</strong>: Create training examples using a large "teacher" model</li>
<li><strong>Fine-Tuning</strong>: Train a smaller "student" model on this data</li>
<li><strong>Optimization</strong>: Convert and compress the model for efficiency</li>
<li><strong>Testing</strong>: Verify the model works correctly</li>
<li><strong>Registration</strong>: Register your model with Azure ML</li>
<li><strong>Deployment</strong>: Download and run the model locally</li>
</ol>
<p>Each notebook is designed to be completed in 5-15 minutes, with clear instructions at each step.</p>
<h2 id="prerequisites-check">Prerequisites Check<a class="headerlink" href="#prerequisites-check" title="Permanent link">&para;</a></h2>
<p>Before you start, ensure you have:</p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>Azure ML Studio access</strong> with compute resources allocated</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>Python 3.10+</strong> installed (already in Azure ML Studio)</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>Basic Python knowledge</strong> (understanding of functions, loops, and imports)</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>Terminal/command line familiarity</strong> (basic git commands)</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> <strong>Internet connectivity</strong> (to access datasets and models)</li>
</ul>
<blockquote>
<p><strong>Important:</strong> This workshop uses Azure ML Studio and requires access to a deployed Azure AI model endpoint. You should have already been provided with the necessary credentials.</p>
</blockquote>
<h2 id="environment-setup">Environment Setup<a class="headerlink" href="#environment-setup" title="Permanent link">&para;</a></h2>
<p>Let's start by setting up your environment and cloning the code repository.</p>
<h3 id="1-access-azure-ml-studio">1. Access Azure ML Studio<a class="headerlink" href="#1-access-azure-ml-studio" title="Permanent link">&para;</a></h3>
<p>Open Azure ML Studio by:
1. Go to <a href="https://ml.azure.com/">Azure ML Studio</a>
2. Sign in with your Azure credentials
3. Select your workspace (provided by your instructor)
4. Navigate to the "Notebooks" section</p>
<h3 id="2-clone-the-repository">2. Clone the Repository<a class="headerlink" href="#2-clone-the-repository" title="Permanent link">&para;</a></h3>
<ol>
<li>In Azure ML Studio, click on the terminal icon at the top right</li>
<li>Run these commands to clone and navigate to the repo:</li>
</ol>
<div class="highlight"><pre><span></span><code>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/microsoft/Build25-LAB329
<span class="nb">cd</span><span class="w"> </span>Build25-LAB329/Lab329/Notebook
</code></pre></div>
<h3 id="3-create-your-environment-file">3. Create Your Environment File<a class="headerlink" href="#3-create-your-environment-file" title="Permanent link">&para;</a></h3>
<p>Create a local environment file to store your Azure credentials:</p>
<div class="highlight"><pre><span></span><code>cp<span class="w"> </span>sample.env<span class="w"> </span>local.env
code<span class="w"> </span>local.env
</code></pre></div>
<p>Add your credentials to the file (these will be provided by your instructor):</p>
<div class="highlight"><pre><span></span><code>TEACHER_MODEL_NAME=DeepSeek-V3
TEACHER_MODEL_ENDPOINT=https://your-endpoint.services.ai.azure.com/models
TEACHER_MODEL_KEY=your-api-key-here
AZUREML_SUBSCRIPTION_ID=your-subscription-id
AZUREML_RESOURCE_GROUP=your-resource-group
AZUREML_WS_NAME=your-workspace-name
</code></pre></div>
<p>Save the file and close the editor.</p>
<h2 id="notebook-by-notebook-guide">Notebook-by-Notebook Guide<a class="headerlink" href="#notebook-by-notebook-guide" title="Permanent link">&para;</a></h2>
<p>This workshop uses 6 Jupyter notebooks that you'll run in sequence. Each notebook builds on the previous one, so it's important to complete them in order.</p>
<p>Let's look at each notebook and what you'll do:</p>
<table>
<thead>
<tr>
<th>Notebook</th>
<th>Purpose</th>
<th>Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>01_AzureML_Distillation</td>
<td>Generate training data using DeepSeek-V3</td>
<td>15 min</td>
</tr>
<tr>
<td>02_AzureML_FineTuningAndConvertByMSOlive</td>
<td>Fine-tune Phi-4-mini with LoRA and optimize</td>
<td>15 min</td>
</tr>
<tr>
<td>03_AzureML_RuningByORTGenAI</td>
<td>Test model inference with ONNX Runtime</td>
<td>10 min</td>
</tr>
<tr>
<td>04_AzureML_RegisterToAzureML</td>
<td>Register model to Azure ML</td>
<td>5 min</td>
</tr>
<tr>
<td>05_Local_Download</td>
<td>Download model for local deployment</td>
<td>5 min</td>
</tr>
<tr>
<td>06_Local_Inference</td>
<td>Run inference locally</td>
<td>10 min</td>
</tr>
</tbody>
</table>
<p>Let's start with the first notebook!</p>
<h2 id="clone-the-github-repo-and-resources-to-your-azure-ml-studio">Clone the GitHub Repo and resources to your Azure ML Studio<a class="headerlink" href="#clone-the-github-repo-and-resources-to-your-azure-ml-studio" title="Permanent link">&para;</a></h2>
<p>Open your <a href="https://ml.azure.com">Azure ML Studio</a></p>
<p><a class="glightbox" href="../images/ML_Studio.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="MLStudio" src="../images/ML_Studio.png" /></a></p>
<p>Select Notebooks</p>
<p><a class="glightbox" href="../images/Notebook_Terminal.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="MLStudioNotebooks" src="../images/Notebook_Terminal.png" /></a></p>
<p>Select Terminal</p>
<p><a class="glightbox" href="../images/ML_Terminal.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="SelectTerminal" src="../images/ML_Terminal.png" /></a></p>
<p>To clone the repository and set up your environment for the lab, follow these steps:</p>
<ol>
<li>
<p><strong>Clone the Repository</strong>: Use the <code>git clone</code> command followed by the repository URL:
   <div class="highlight"><pre><span></span><code>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/microsoft/Build25-LAB329<span class="w"> </span>
</code></pre></div></p>
</li>
<li>
<p><strong>Access the Cloned Repository</strong>: Navigate to the directory of the cloned repository:
   <div class="highlight"><pre><span></span><code><span class="nb">cd</span><span class="w"> </span>Build25-LAB329
</code></pre></div></p>
</li>
<li>
<p><strong>Navigate to the Lab Directory</strong>: Go to the Lab329 folder containing the notebooks:
   <div class="highlight"><pre><span></span><code><span class="nb">cd</span><span class="w"> </span>Lab329/Notebook
</code></pre></div></p>
</li>
<li>
<p><strong>Create Your Environment File</strong>: Copy the sample environment file and rename it to local.env:
   <div class="highlight"><pre><span></span><code>cp<span class="w"> </span>sample.env<span class="w"> </span>local.env
</code></pre></div></p>
</li>
<li>
<p><strong>Edit Your Environment File</strong>: Update the local.env file with your Azure credentials using a text editor:
   <div class="highlight"><pre><span></span><code>code<span class="w"> </span>local.env
</code></pre></div></p>
</li>
</ol>
<p>Login with your azure creditional </p>
<div class="highlight"><pre><span></span><code>az login --identity
</code></pre></div>
<p>Now youâ€™re ready to work with the repository on your Azure ML Studio!</p>
<h2 id="step-1-generate-training-data-15-min">Step 1: Generate Training Data (15 min)<a class="headerlink" href="#step-1-generate-training-data-15-min" title="Permanent link">&para;</a></h2>
<p><strong>Notebook:</strong> <code>01.AzureML_Distillation.ipynb</code></p>
<p><strong>Purpose:</strong> Create a training dataset by asking a large teacher model (DeepSeek-V3) to answer multiple-choice questions.</p>
<h4 id="instructions">Instructions:<a class="headerlink" href="#instructions" title="Permanent link">&para;</a></h4>
<ol>
<li>
<p><strong>Open the notebook</strong> from the left file explorer panel in Azure ML Studio</p>
</li>
<li>
<p><strong>Read the purpose and overview</strong> at the top of the notebook </p>
</li>
<li>
<p><strong>Install required packages</strong></p>
</li>
<li>Run the first cell to install dependencies</li>
<li>
<p>Look for successful installation messages before continuing</p>
</li>
<li>
<p><strong>Load environment variables</strong></p>
</li>
<li>Run the environment variables cell</li>
<li>
<p>Verify your teacher model endpoint is correctly loaded</p>
</li>
<li>
<p><strong>Load the dataset</strong></p>
</li>
<li>Run the cell to load the CommonSenseQA dataset</li>
<li>
<p>You should see output showing the dataset was successfully loaded</p>
</li>
<li>
<p><strong>Process questions and get teacher responses</strong></p>
</li>
<li>Run the cells that process questions for the teacher model</li>
<li>Watch the progress as the teacher model generates answers</li>
<li>
<p>Note: This may take 5-10 minutes depending on the number of questions</p>
</li>
<li>
<p><strong>Save the teacher's responses</strong></p>
</li>
<li>Run the final cells to save responses to <code>data/train_data.jsonl</code></li>
<li>Verify the file was created successfully</li>
</ol>
<h4 id="key-outputs">Key Outputs:<a class="headerlink" href="#key-outputs" title="Permanent link">&para;</a></h4>
<ul>
<li>A JSONL file with questions and expert answers from the teacher model</li>
<li>This file will be used to train your student model in the next notebook</li>
</ul>
<h2 id="troubleshooting-guide">Troubleshooting Guide<a class="headerlink" href="#troubleshooting-guide" title="Permanent link">&para;</a></h2>
<p>If you encounter issues during the workshop, use this guide to resolve common problems:</p>
<h3 id="environment-and-setup-issues">Environment and Setup Issues<a class="headerlink" href="#environment-and-setup-issues" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Authentication errors</strong>:</li>
<li>Error: "Failed to authenticate to Azure"</li>
<li>Solution: Verify your local.env file has the correct values</li>
<li>
<p>Fix: Run <code>az login</code> in the terminal to refresh your login</p>
</li>
<li>
<p><strong>Missing environment variables</strong>:</p>
</li>
<li>Error: "NameError: name 'xyz' is not defined"</li>
<li>Solution: Make sure you've run all initialization cells</li>
<li>
<p>Fix: Create or update your local.env file with the required values</p>
</li>
<li>
<p><strong>Package installation failures</strong>:</p>
</li>
<li>Error: "ERROR: Could not install packages..."</li>
<li>Solution: Ensure you have internet connectivity and proper permissions</li>
<li>Fix: Try installing one package at a time or specify --user flag</li>
</ol>
<h3 id="teacher-model-issues">Teacher Model Issues<a class="headerlink" href="#teacher-model-issues" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Connection to teacher model fails</strong>:</li>
<li>Error: "Unable to connect to endpoint"</li>
<li>Solution: Check your API key and endpoint URL</li>
<li>
<p>Fix: Update the TEACHER_MODEL_* values in local.env</p>
</li>
<li>
<p><strong>Dataset loading errors</strong>:</p>
</li>
<li>Error: "Failed to download/load dataset"</li>
<li>Solution: Check internet connectivity and reduce batch size</li>
<li>Fix: Try <code>dataset = load_dataset("tau/commonsense_qa", split="train[:10]")</code> for a smaller sample</li>
</ol>
<h3 id="step-1-generate-training-data-from-a-teacher-model-15-minutes">Step 1: Generate Training Data from a Teacher Model (15 minutes)<a class="headerlink" href="#step-1-generate-training-data-from-a-teacher-model-15-minutes" title="Permanent link">&para;</a></h3>
<p>Open the <a href="../Lab329/Notebook/01.AzureML_Distillation.ipynb"><code>01.AzureML_Distillation.ipynb</code></a> notebook and follow these steps to generate training data for your student model:</p>
<ol>
<li>
<p><strong>Run the notebook cell by cell</strong>, starting with package installation:
   <div class="highlight"><pre><span></span><code><span class="n">pip</span> <span class="n">install</span> <span class="n">python</span><span class="o">-</span><span class="n">dotenv</span>
<span class="n">pip</span> <span class="n">install</span> <span class="n">datasets</span> <span class="o">-</span><span class="n">U</span>
<span class="n">pip</span> <span class="n">install</span> <span class="n">azure</span><span class="o">-</span><span class="n">ai</span><span class="o">-</span><span class="n">inference</span>
</code></pre></div></p>
</li>
<li>
<p><strong>Load and prepare a dataset</strong>:
   <div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">ABC</span>

<span class="c1"># Define a class to handle the input dataset</span>
<span class="k">class</span><span class="w"> </span><span class="nc">InputDataset</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_data_file_name</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_data_file_name</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_data_file_name</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

<span class="c1"># Specific implementation for the QA dataset</span>
<span class="k">class</span><span class="w"> </span><span class="nc">CQnAHuggingFaceInputDataset</span><span class="p">(</span><span class="n">InputDataset</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load_hf_dataset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dataset_name</span><span class="p">,</span>
        <span class="n">train_sample_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">val_sample_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">test_sample_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">train_split_name</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span>
        <span class="n">val_split_name</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
        <span class="n">test_split_name</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># Load dataset and create splits</span>
        <span class="n">full_dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">)</span>
        <span class="n">train_data</span> <span class="o">=</span> <span class="n">full_dataset</span><span class="p">[</span><span class="n">train_split_name</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">train_sample_size</span><span class="p">))</span>
        <span class="n">val_data</span> <span class="o">=</span> <span class="n">full_dataset</span><span class="p">[</span><span class="n">val_split_name</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">val_sample_size</span><span class="p">))</span>
        <span class="n">test_data</span> <span class="o">=</span> <span class="n">full_dataset</span><span class="p">[</span><span class="n">test_split_name</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">test_sample_size</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span><span class="p">,</span> <span class="n">test_data</span>
</code></pre></div></p>
</li>
<li>
<p><strong>Sample data from a Hugging Face dataset</strong>:
   <div class="highlight"><pre><span></span><code><span class="c1"># Define sample sizes</span>
<span class="n">train_sample_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">val_sample_size</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># We&#39;ll use the commonsense QA dataset</span>
<span class="n">dataset_name</span> <span class="o">=</span> <span class="s2">&quot;tau/commonsense_qa&quot;</span>
<span class="n">input_dataset</span> <span class="o">=</span> <span class="n">CQnAHuggingFaceInputDataset</span><span class="p">()</span>

<span class="c1"># Load the dataset</span>
<span class="n">train</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">input_dataset</span><span class="o">.</span><span class="n">load_hf_dataset</span><span class="p">(</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">dataset_name</span><span class="p">,</span>
    <span class="n">train_sample_size</span><span class="o">=</span><span class="n">train_sample_size</span><span class="p">,</span>
    <span class="n">val_sample_size</span><span class="o">=</span><span class="n">val_sample_size</span><span class="p">,</span>
    <span class="n">train_split_name</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span>
    <span class="n">val_split_name</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></p>
</li>
<li>
<p><strong>Format the questions for the teacher model</strong>:
   <div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>

<span class="c1"># Create directory for data</span>
<span class="err">!</span> <span class="n">mkdir</span> <span class="o">-</span><span class="n">p</span> <span class="n">data</span>
<span class="n">train_data_path</span> <span class="o">=</span> <span class="s2">&quot;data/train_original_data.jsonl&quot;</span>

<span class="c1"># Define prompts</span>
<span class="n">system_prompt</span> <span class="o">=</span> <span class="s2">&quot;You are a helpful assistant. Your output should only be one of the five choices: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, or &#39;E&#39;.&quot;</span>
<span class="n">user_prompt_template</span> <span class="o">=</span> <span class="s2">&quot;Answer the following multiple-choice question by selecting the correct option.</span><span class="se">\n\n</span><span class="s2">Question: </span><span class="si">{question}</span><span class="se">\n</span><span class="s2">Answer Choices:</span><span class="se">\n</span><span class="si">{answer_choices}</span><span class="s2">&quot;</span>

<span class="c1"># Format each question</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">train</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[]}</span>
    <span class="n">data</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span>
            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">system_prompt</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">)</span>
    <span class="n">question</span><span class="p">,</span> <span class="n">choices</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s2">&quot;question&quot;</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="s2">&quot;choices&quot;</span><span class="p">]</span>
    <span class="n">labels</span><span class="p">,</span> <span class="n">choice_list</span> <span class="o">=</span> <span class="n">choices</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">],</span> <span class="n">choices</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span>
    <span class="n">answer_choices</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;(</span><span class="si">{}</span><span class="s2">) </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">choice_list</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
    <span class="p">]</span>
    <span class="n">answer_choices</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">answer_choices</span><span class="p">)</span>
    <span class="n">data</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">user_prompt_template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">question</span><span class="o">=</span><span class="n">question</span><span class="p">,</span> <span class="n">answer_choices</span><span class="o">=</span><span class="n">answer_choices</span>
            <span class="p">),</span>
        <span class="p">}</span>
    <span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">train_data_path</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></p>
</li>
<li>
<p><strong>Load credentials and connect to the teacher model</strong>:
   <div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">dotenv</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">azure.ai.inference</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatCompletionsClient</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">azure.ai.inference.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">SystemMessage</span><span class="p">,</span> <span class="n">UserMessage</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">azure.core.credentials</span><span class="w"> </span><span class="kn">import</span> <span class="n">AzureKeyCredential</span>

<span class="c1"># Load environment variables</span>
<span class="n">load_dotenv</span><span class="p">()</span>

<span class="n">teacher_model_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;TEACHER_MODEL_NAME&#39;</span><span class="p">)</span>
<span class="n">teacher_model_endpoint_url</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;TEACHER_MODEL_ENDPOINT&#39;</span><span class="p">)</span>
<span class="n">teacher_model_api_key</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;TEACHER_MODEL_KEY&#39;</span><span class="p">)</span>

<span class="c1"># Set up client</span>
<span class="n">endpoint</span> <span class="o">=</span> <span class="n">teacher_model_endpoint_url</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="n">teacher_model_name</span>
<span class="n">key</span> <span class="o">=</span> <span class="n">teacher_model_api_key</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">ChatCompletionsClient</span><span class="p">(</span><span class="n">endpoint</span><span class="o">=</span><span class="n">endpoint</span><span class="p">,</span> <span class="n">credential</span><span class="o">=</span><span class="n">AzureKeyCredential</span><span class="p">(</span><span class="n">key</span><span class="p">))</span>
</code></pre></div></p>
</li>
<li>
<p><strong>Generate responses using the teacher model</strong>:
   <div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">process_question</span><span class="p">(</span><span class="n">question_data</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">messages</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">msg</span> <span class="ow">in</span> <span class="n">question_data</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">msg</span><span class="p">[</span><span class="s2">&quot;role&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;system&quot;</span><span class="p">:</span>
                <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">SystemMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">msg</span><span class="p">[</span><span class="s2">&quot;content&quot;</span><span class="p">]))</span>
            <span class="k">elif</span> <span class="n">msg</span><span class="p">[</span><span class="s2">&quot;role&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;user&quot;</span><span class="p">:</span>
                <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">UserMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">msg</span><span class="p">[</span><span class="s2">&quot;content&quot;</span><span class="p">]))</span>

        <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">complete</span><span class="p">(</span>
            <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
            <span class="n">max_tokens</span><span class="o">=</span><span class="mi">100</span>  <span class="c1"># Short answers (A, B, C, D, or E)</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="n">question_data</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="s2">&quot;content&quot;</span><span class="p">],</span>
            <span class="s2">&quot;response&quot;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">,</span>
            <span class="s2">&quot;full_response&quot;</span><span class="p">:</span> <span class="n">response</span>
        <span class="p">}</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="n">question_data</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="s2">&quot;content&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">question_data</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;Error&quot;</span><span class="p">,</span>
            <span class="s2">&quot;response&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Error: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="s2">&quot;full_response&quot;</span><span class="p">:</span> <span class="kc">None</span>
        <span class="p">}</span>

<span class="c1"># Process all questions</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">train_data_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Processing questions from </span><span class="si">{</span><span class="n">train_data_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">file</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>  <span class="c1"># Skip empty lines</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">question_data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Processing question </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">process_question</span><span class="p">(</span><span class="n">question_data</span><span class="p">)</span>
                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Question </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> response: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;response&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error processing line </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></p>
</li>
<li>
<p><strong>Save the teacher's responses for student model training</strong>:
   <div class="highlight"><pre><span></span><code><span class="n">output_file_path</span> <span class="o">=</span> <span class="s2">&quot;./data/train_data.jsonl&quot;</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">output_file_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
        <span class="c1"># Create the simplified output format</span>
        <span class="n">output_line</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;Question&quot;</span><span class="p">:</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;question&quot;</span><span class="p">],</span>
            <span class="s2">&quot;Answer&quot;</span><span class="p">:</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;response&quot;</span><span class="p">]</span>
        <span class="p">}</span>

        <span class="c1"># Write as JSONL (one JSON object per line)</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">output_line</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div></p>
</li>
</ol>
<p>This process:
- Loads a multiple-choice question dataset from Hugging Face
- Formats each question with a clear system prompt and instruction
- Sends the questions to your teacher model (using Azure AI Foundry MAI endpoint)
- Collects the high-quality responses from the larger model
- Creates a training dataset that pairs questions with expert answers
- Formats the output for use in the next step of model distillation</p>
<p>The resulting <code>train_data.jsonl</code> file will be used in Step 2 to fine-tune your smaller student model.</p>
<h3 id="step-2-fine-tune-and-optimize-15-min">Step 2: Fine-tune and Optimize (15 min)<a class="headerlink" href="#step-2-fine-tune-and-optimize-15-min" title="Permanent link">&para;</a></h3>
<p><strong>Notebook:</strong> <code>02.AzureML_FineTuningAndConvertByMSOlive.ipynb</code></p>
<p><strong>Purpose:</strong> Transform the small student model by fine-tuning it on the training data generated from the teacher model, and optimize it for deployment.</p>
<h4 id="instructions_1">Instructions:<a class="headerlink" href="#instructions_1" title="Permanent link">&para;</a></h4>
<ol>
<li>
<p><strong>Open the notebook</strong> from the file explorer in Azure ML Studio</p>
</li>
<li>
<p><strong>Install required packages</strong></p>
</li>
<li>Run the package installation cell:
   <div class="highlight"><pre><span></span><code><span class="n">pip</span> <span class="n">install</span> <span class="n">torch</span> <span class="n">torchvision</span> <span class="n">torchaudio</span> <span class="o">--</span><span class="n">index</span><span class="o">-</span><span class="n">url</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">download</span><span class="o">.</span><span class="n">pytorch</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="n">whl</span><span class="o">/</span><span class="n">cu124</span> <span class="o">-</span><span class="n">U</span>
<span class="n">pip</span> <span class="n">install</span> <span class="n">olive</span><span class="o">-</span><span class="n">ai</span><span class="p">[</span><span class="n">auto</span><span class="o">-</span><span class="n">opt</span><span class="p">]</span> <span class="o">-</span><span class="n">U</span>
<span class="n">pip</span> <span class="n">install</span> <span class="n">onnxruntime</span><span class="o">-</span><span class="n">genai</span><span class="o">==</span><span class="mf">0.7.0</span> <span class="o">--</span><span class="n">pre</span>
<span class="n">pip</span> <span class="n">install</span> <span class="n">peft</span>
</code></pre></div></li>
<li>
<p>Wait for all packages to install successfully</p>
</li>
<li>
<p><strong>Fine-tune with LoRA</strong></p>
</li>
<li>Run the cell containing the olive finetune command:
   <div class="highlight"><pre><span></span><code><span class="err">!</span><span class="n">olive</span> <span class="n">finetune</span> \
    <span class="o">--</span><span class="n">method</span> <span class="n">lora</span> \
    <span class="o">--</span><span class="n">model_name_or_path</span> <span class="n">azureml</span><span class="p">:</span><span class="o">//</span><span class="n">registries</span><span class="o">/</span><span class="n">azureml</span><span class="o">/</span><span class="n">models</span><span class="o">/</span><span class="n">Phi</span><span class="o">-</span><span class="mi">4</span><span class="o">-</span><span class="n">mini</span><span class="o">-</span><span class="n">instruct</span><span class="o">/</span><span class="n">versions</span><span class="o">/</span><span class="mi">1</span> \
    <span class="o">--</span><span class="n">trust_remote_code</span> \
    <span class="o">--</span><span class="n">data_name</span> <span class="n">json</span> \
    <span class="o">--</span><span class="n">data_files</span> <span class="o">./</span><span class="n">data</span><span class="o">/</span><span class="n">train_data</span><span class="o">.</span><span class="n">jsonl</span> \
    <span class="o">--</span><span class="n">text_template</span> <span class="s2">&quot;&lt;|user|&gt;</span><span class="si">{Question}</span><span class="s2">&lt;|end|&gt;&lt;|assistant|&gt;</span><span class="si">{Answer}</span><span class="s2">&lt;|end|&gt;&quot;</span> \
    <span class="o">--</span><span class="n">max_steps</span> <span class="mi">100</span> \
    <span class="o">--</span><span class="n">output_path</span> <span class="n">models</span><span class="o">/</span><span class="n">phi</span><span class="o">-</span><span class="mi">4</span><span class="o">-</span><span class="n">mini</span><span class="o">/</span><span class="n">ft</span> \
    <span class="o">--</span><span class="n">target_modules</span> <span class="s2">&quot;q_proj&quot;</span><span class="p">,</span><span class="s2">&quot;k_proj&quot;</span><span class="p">,</span><span class="s2">&quot;v_proj&quot;</span><span class="p">,</span><span class="s2">&quot;o_proj&quot;</span><span class="p">,</span><span class="s2">&quot;gate_proj&quot;</span><span class="p">,</span><span class="s2">&quot;up_proj&quot;</span><span class="p">,</span><span class="s2">&quot;down_proj&quot;</span> \
    <span class="o">--</span><span class="n">log_level</span> <span class="mi">1</span>
</code></pre></div></li>
<li>This will take approximately 5-10 minutes to complete</li>
<li>
<p>Watch the output for "Fine-tuning complete" message</p>
</li>
<li>
<p><strong>Convert to ONNX and quantize</strong></p>
</li>
<li>Run the model optimization cell:
   <div class="highlight"><pre><span></span><code><span class="err">!</span><span class="n">olive</span> <span class="n">auto</span><span class="o">-</span><span class="n">opt</span> \
    <span class="o">--</span><span class="n">model_name_or_path</span> <span class="n">azureml</span><span class="p">:</span><span class="o">//</span><span class="n">registries</span><span class="o">/</span><span class="n">azureml</span><span class="o">/</span><span class="n">models</span><span class="o">/</span><span class="n">Phi</span><span class="o">-</span><span class="mi">4</span><span class="o">-</span><span class="n">mini</span><span class="o">-</span><span class="n">instruct</span><span class="o">/</span><span class="n">versions</span><span class="o">/</span><span class="mi">1</span> \
    <span class="o">--</span><span class="n">adapter_path</span> <span class="n">models</span><span class="o">/</span><span class="n">phi</span><span class="o">-</span><span class="mi">4</span><span class="o">-</span><span class="n">mini</span><span class="o">/</span><span class="n">ft</span><span class="o">/</span><span class="n">adapter</span> \
    <span class="o">--</span><span class="n">device</span> <span class="n">cpu</span> \
    <span class="o">--</span><span class="n">provider</span> <span class="n">CPUExecutionProvider</span> \
    <span class="o">--</span><span class="n">use_model_builder</span> \
    <span class="o">--</span><span class="n">precision</span> <span class="n">int4</span> \
    <span class="o">--</span><span class="n">output_path</span> <span class="n">models</span><span class="o">/</span><span class="n">phi</span><span class="o">-</span><span class="mi">4</span><span class="o">-</span><span class="n">mini</span><span class="o">/</span><span class="n">onnx</span> \
    <span class="o">--</span><span class="n">log_level</span> <span class="mi">1</span>
</code></pre></div></li>
<li>This will take approximately 5-10 minutes</li>
<li>
<p>The optimization reduces model size by ~75%</p>
</li>
<li>
<p><strong>Verify the output directory</strong></p>
</li>
<li>Run the cell to list the files in the output directory</li>
<li>Ensure both model files and adapter files are present</li>
</ol>
<h4 id="key-outputs_1">Key Outputs:<a class="headerlink" href="#key-outputs_1" title="Permanent link">&para;</a></h4>
<ul>
<li>A LoRA adapter in <code>models/phi-4-mini/ft/adapter</code></li>
<li>A quantized ONNX model in <code>models/phi-4-mini/onnx/model</code></li>
<li>These files will be used for inference in the next notebook</li>
</ul>
<h3 id="step-3-test-your-onnx-model-10-min">Step 3: Test Your ONNX Model (10 min)<a class="headerlink" href="#step-3-test-your-onnx-model-10-min" title="Permanent link">&para;</a></h3>
<p><strong>Notebook:</strong> <code>03.AzureML_RuningByORTGenAI.ipynb</code></p>
<p><strong>Purpose:</strong> Test the optimized model using ONNX Runtime GenAI to verify its performance on multiple-choice questions.</p>
<h4 id="instructions_2">Instructions:<a class="headerlink" href="#instructions_2" title="Permanent link">&para;</a></h4>
<ol>
<li>
<p><strong>Open the notebook</strong> from the file explorer</p>
</li>
<li>
<p><strong>Import libraries and load the model</strong></p>
</li>
<li>Run the import and model loading cells:
   <div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">onnxruntime_genai</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">og</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">model_folder</span> <span class="o">=</span> <span class="s2">&quot;./models/phi-4-mini/onnx/model&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">og</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">model_folder</span><span class="p">)</span>
</code></pre></div></li>
<li>
<p>Verify the model loads without errors</p>
</li>
<li>
<p><strong>Load the adapter</strong></p>
</li>
<li>Run the adapter loading cell:
   <div class="highlight"><pre><span></span><code><span class="n">adapters</span> <span class="o">=</span> <span class="n">og</span><span class="o">.</span><span class="n">Adapters</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">adapters</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;./models/phi-4-mini/onnx/model/adapter_weights.onnx_adapter&#39;</span><span class="p">,</span> <span class="s2">&quot;qa_choice&quot;</span><span class="p">)</span>
</code></pre></div></li>
<li>
<p>Check for confirmation that the adapter loaded successfully</p>
</li>
<li>
<p><strong>Set up the tokenizer</strong></p>
</li>
<li>
<p>Run the tokenizer setup cells:
   <div class="highlight"><pre><span></span><code><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">og</span><span class="o">.</span><span class="n">Tokenizer</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">tokenizer_stream</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">create_stream</span><span class="p">()</span>

<span class="n">search_options</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">search_options</span><span class="p">[</span><span class="s1">&#39;max_length&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">102</span>
<span class="n">search_options</span><span class="p">[</span><span class="s1">&#39;past_present_share_buffer&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">search_options</span><span class="p">[</span><span class="s1">&#39;repeat_penalty&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.1</span>
<span class="n">search_options</span><span class="p">[</span><span class="s1">&#39;temperature&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.7</span>
</code></pre></div></p>
</li>
<li>
<p><strong>Test the model on example questions</strong></p>
</li>
<li>Run the inference cells with example multiple-choice questions</li>
<li>The model should generate answers (A, B, C, D, or E)</li>
<li>
<p>Compare the model's answers to the expected answers</p>
</li>
<li>
<p><strong>Try your own questions</strong> (optional)</p>
</li>
<li>Modify the example question in the last cell</li>
<li>Run the cell to see how the model performs on your question</li>
</ol>
<h4 id="key-points">Key Points:<a class="headerlink" href="#key-points" title="Permanent link">&para;</a></h4>
<ul>
<li>ONNX Runtime GenAI provides optimized inference for your model</li>
<li>The model should run efficiently on CPU, without requiring a GPU</li>
<li>The adapter contains the knowledge learned from the teacher model</li>
<li>The model should respond with the correct multiple-choice answer most of the time</li>
</ul>
<h3 id="step-4-register-to-azure-ml-5-min">Step 4: Register to Azure ML (5 min)<a class="headerlink" href="#step-4-register-to-azure-ml-5-min" title="Permanent link">&para;</a></h3>
<p><strong>Notebook:</strong> <code>04.AzureML_RegisterToAzureML.ipynb</code></p>
<p><strong>Purpose:</strong> Register your optimized model to Azure ML for version tracking, sharing, and future deployment.</p>
<h4 id="instructions_3">Instructions:<a class="headerlink" href="#instructions_3" title="Permanent link">&para;</a></h4>
<ol>
<li>
<p><strong>Open the notebook</strong> from the file explorer</p>
</li>
<li>
<p><strong>Install required packages</strong></p>
</li>
<li>
<p>Run the package installation cell if needed:
   <div class="highlight"><pre><span></span><code><span class="n">pip</span> <span class="n">install</span> <span class="n">azure</span><span class="o">-</span><span class="n">ai</span><span class="o">-</span><span class="n">ml</span>
<span class="n">pip</span> <span class="n">install</span> <span class="n">azure</span><span class="o">-</span><span class="n">identity</span>
<span class="n">pip</span> <span class="n">install</span> <span class="n">python</span><span class="o">-</span><span class="n">dotenv</span>
</code></pre></div></p>
</li>
<li>
<p><strong>Import libraries and load environment</strong></p>
</li>
<li>Run the import cells:
   <div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dotenv</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">azure.ai.ml</span><span class="w"> </span><span class="kn">import</span> <span class="n">MLClient</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">azure.ai.ml.entities</span><span class="w"> </span><span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">azure.ai.ml.constants</span><span class="w"> </span><span class="kn">import</span> <span class="n">AssetTypes</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">azure.identity</span><span class="w"> </span><span class="kn">import</span> <span class="n">DefaultAzureCredential</span>
</code></pre></div></li>
<li>Run the environment loading cell:
   <div class="highlight"><pre><span></span><code><span class="n">load_dotenv</span><span class="p">()</span>

<span class="n">subscription_id</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;AZUREML_SUBSCRIPTION_ID&#39;</span><span class="p">)</span>
<span class="n">resource_group</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;AZUREML_RESOURCE_GROUP&#39;</span><span class="p">)</span>
<span class="n">workspace</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;AZUREML_WS_NAME&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Subscription ID: </span><span class="si">{</span><span class="n">subscription_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Resource Group: </span><span class="si">{</span><span class="n">resource_group</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Workspace Name: </span><span class="si">{</span><span class="n">workspace</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></li>
<li>
<p>Verify your Azure ML workspace information is displayed correctly</p>
</li>
<li>
<p><strong>Create ML client and connect to Azure ML</strong></p>
</li>
<li>
<p>Run the ML client creation cell:
   <div class="highlight"><pre><span></span><code><span class="n">ml_client</span> <span class="o">=</span> <span class="n">MLClient</span><span class="p">(</span><span class="n">DefaultAzureCredential</span><span class="p">(),</span> <span class="n">subscription_id</span><span class="p">,</span> <span class="n">resource_group</span><span class="p">,</span> <span class="n">workspace</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Successfully connected to Azure ML workspace&quot;</span><span class="p">)</span>
</code></pre></div></p>
</li>
<li>
<p><strong>Register your model</strong></p>
</li>
<li>Run the model registration cell:
   <div class="highlight"><pre><span></span><code><span class="n">file_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span>
    <span class="n">path</span><span class="o">=</span><span class="s2">&quot;models/phi-4-mini/onnx&quot;</span><span class="p">,</span>
    <span class="nb">type</span><span class="o">=</span><span class="n">AssetTypes</span><span class="o">.</span><span class="n">CUSTOM_MODEL</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fine-tuning-phi-4-mini-onnx-int4-cpu&quot;</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Fine tuning by MSOlive&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">registered_model</span> <span class="o">=</span> <span class="n">ml_client</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">create_or_update</span><span class="p">(</span><span class="n">file_model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model registered with name: </span><span class="si">{</span><span class="n">registered_model</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">, version: </span><span class="si">{</span><span class="n">registered_model</span><span class="o">.</span><span class="n">version</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></li>
<li>
<p>Wait for confirmation that the model was registered successfully</p>
</li>
<li>
<p><strong>Verify registration</strong></p>
</li>
<li>Run the cell to list registered models:
   <div class="highlight"><pre><span></span><code><span class="n">models</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ml_client</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">list</span><span class="p">())</span>
<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">, Version: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">version</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></li>
<li>Verify your model appears in the list</li>
</ol>
<h4 id="key-outputs_2">Key Outputs:<a class="headerlink" href="#key-outputs_2" title="Permanent link">&para;</a></h4>
<ul>
<li>Your model registered in Azure ML with a unique name and version</li>
<li>This registration makes your model discoverable and shareable with others</li>
<li>You'll use this registered model for download in the next notebook</li>
</ul>
<h3 id="step-5-download-the-model-5-min">Step 5: Download the Model (5 min)<a class="headerlink" href="#step-5-download-the-model-5-min" title="Permanent link">&para;</a></h3>
<p><strong>Notebook:</strong> <code>05.Local_Download.ipynb</code></p>
<p><strong>Purpose:</strong> Download the registered model from Azure ML to your local machine for local deployment and inference.</p>
<h4 id="instructions_4">Instructions:<a class="headerlink" href="#instructions_4" title="Permanent link">&para;</a></h4>
<ol>
<li><strong>Important:</strong> This notebook should be run on your local machine, not in Azure ML Studio</li>
<li>Download the notebook from the file explorer in Azure ML to your local computer</li>
<li>
<p>Open it in a local Jupyter environment (VS Code, JupyterLab, etc.)</p>
</li>
<li>
<p><strong>Install required packages</strong></p>
</li>
<li>
<p>Run the package installation cell:
   <div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">subprocess</span>

<span class="k">def</span><span class="w"> </span><span class="nf">install_package</span><span class="p">(</span><span class="n">package_name</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="nb">__import__</span><span class="p">(</span><span class="n">package_name</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ“ </span><span class="si">{</span><span class="n">package_name</span><span class="si">}</span><span class="s2"> is already installed&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Installing </span><span class="si">{</span><span class="n">package_name</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
        <span class="n">subprocess</span><span class="o">.</span><span class="n">check_call</span><span class="p">([</span><span class="n">sys</span><span class="o">.</span><span class="n">executable</span><span class="p">,</span> <span class="s1">&#39;-m&#39;</span><span class="p">,</span> <span class="s1">&#39;pip&#39;</span><span class="p">,</span> <span class="s1">&#39;install&#39;</span><span class="p">,</span> <span class="n">package_name</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ“ </span><span class="si">{</span><span class="n">package_name</span><span class="si">}</span><span class="s2"> installed successfully&quot;</span><span class="p">)</span>

<span class="n">install_package</span><span class="p">(</span><span class="s1">&#39;python-dotenv&#39;</span><span class="p">)</span>
<span class="n">install_package</span><span class="p">(</span><span class="s1">&#39;azure-identity&#39;</span><span class="p">)</span>
<span class="n">install_package</span><span class="p">(</span><span class="s1">&#39;azure-ai-ml&#39;</span><span class="p">)</span>
</code></pre></div></p>
</li>
<li>
<p><strong>Create local.env file</strong></p>
</li>
<li>Create a <code>local.env</code> file in the same directory as the notebook</li>
<li>
<p>Add your Azure ML credentials to the file:
   <div class="highlight"><pre><span></span><code>AZUREML_SUBSCRIPTION_ID=your-subscription-id
AZUREML_RESOURCE_GROUP=your-resource-group
AZUREML_WS_NAME=your-workspace-name
</code></pre></div></p>
</li>
<li>
<p><strong>Load environment and create ML client</strong></p>
</li>
<li>Run the environment loading cells</li>
<li>Run the ML client creation cell:
   <div class="highlight"><pre><span></span><code><span class="n">ml_client</span> <span class="o">=</span> <span class="n">MLClient</span><span class="p">(</span><span class="n">DefaultAzureCredential</span><span class="p">(),</span> <span class="n">subscription_id</span><span class="p">,</span> <span class="n">resource_group</span><span class="p">,</span> <span class="n">workspace</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Successfully connected to Azure ML workspace&quot;</span><span class="p">)</span>
</code></pre></div></li>
<li>
<p>Verify successful connection to Azure ML</p>
</li>
<li>
<p><strong>List available models</strong></p>
</li>
<li>Run the model listing cell:
   <div class="highlight"><pre><span></span><code><span class="n">models</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ml_client</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">list</span><span class="p">())</span>
<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; - </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2"> (version: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">version</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
</code></pre></div></li>
<li>
<p>Confirm your registered model is in the list</p>
</li>
<li>
<p><strong>Download your model</strong></p>
</li>
<li>Run the model download cell:
   <div class="highlight"><pre><span></span><code><span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;fine-tuning-phi-4-mini-onnx-int4-cpu&quot;</span>
<span class="n">model_version</span> <span class="o">=</span> <span class="mi">1</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Starting download of model: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> (version </span><span class="si">{</span><span class="n">model_version</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

<span class="n">download_path</span> <span class="o">=</span> <span class="n">ml_client</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="n">model_version</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model downloaded to: </span><span class="si">{</span><span class="n">download_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></li>
<li>
<p>Wait for the download to complete (may take a few minutes)</p>
</li>
<li>
<p><strong>Calculate model statistics</strong></p>
</li>
<li>Run the cells to calculate and display model size and file count</li>
<li>Note the total size, which should be much smaller than the original model</li>
</ol>
<h4 id="key-outputs_3">Key Outputs:<a class="headerlink" href="#key-outputs_3" title="Permanent link">&para;</a></h4>
<ul>
<li>A downloaded model on your local machine</li>
<li>Information about the model size and files</li>
<li>The model location for use in local inference</li>
</ul>
<h3 id="step-6-local-inference-10-min">Step 6: Local Inference (10 min)<a class="headerlink" href="#step-6-local-inference-10-min" title="Permanent link">&para;</a></h3>
<p><strong>Notebook:</strong> <code>06.Local_Inference.ipynb</code></p>
<p><strong>Purpose:</strong> Run the optimized model on your local machine to demonstrate its ability to answer questions without cloud resources.</p>
<h4 id="instructions_5">Instructions:<a class="headerlink" href="#instructions_5" title="Permanent link">&para;</a></h4>
<ol>
<li><strong>Run the notebook locally</strong></li>
<li>Open the notebook on your local machine in a Jupyter environment</li>
<li>
<p>This notebook should be run on the same machine where you downloaded the model</p>
</li>
<li>
<p><strong>Install ONNX Runtime GenAI</strong></p>
</li>
<li>
<p>Run the package installation cell:
   <div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">install_package</span><span class="p">(</span><span class="n">package_name</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="nb">__import__</span><span class="p">(</span><span class="n">package_name</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ“ </span><span class="si">{</span><span class="n">package_name</span><span class="si">}</span><span class="s2"> is already installed&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Installing </span><span class="si">{</span><span class="n">package_name</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
        <span class="n">subprocess</span><span class="o">.</span><span class="n">check_call</span><span class="p">([</span><span class="n">sys</span><span class="o">.</span><span class="n">executable</span><span class="p">,</span> <span class="s1">&#39;-m&#39;</span><span class="p">,</span> <span class="s1">&#39;pip&#39;</span><span class="p">,</span> <span class="s1">&#39;install&#39;</span><span class="p">,</span> <span class="n">package_name</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ“ </span><span class="si">{</span><span class="n">package_name</span><span class="si">}</span><span class="s2"> installed successfully&quot;</span><span class="p">)</span>

<span class="n">install_package</span><span class="p">(</span><span class="s1">&#39;onnxruntime-genai&#39;</span><span class="p">)</span>
</code></pre></div></p>
</li>
<li>
<p><strong>Set the model path</strong></p>
</li>
<li>Update the model path to where your model was downloaded:
   <div class="highlight"><pre><span></span><code><span class="n">model_path</span> <span class="o">=</span> <span class="s2">&quot;./fine-tuning-phi-4-mini-onnx-int4-cpu/1/model&quot;</span>

<span class="c1"># Verify the model files exist</span>
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">model_path</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model found at path: </span><span class="si">{</span><span class="n">model_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model files:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">model_path</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; - </span><span class="si">{</span><span class="n">file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></li>
<li>
<p>Verify the model files are found</p>
</li>
<li>
<p><strong>Load the model and adapter</strong></p>
</li>
<li>Run the model loading cells:
   <div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">og</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;âœ“ Model loaded successfully!&quot;</span><span class="p">)</span>

<span class="n">adapters</span> <span class="o">=</span> <span class="n">og</span><span class="o">.</span><span class="n">Adapters</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">adapter_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="s2">&quot;adapter_weights.onnx_adapter&quot;</span><span class="p">)</span>
<span class="n">adapters</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">adapter_path</span><span class="p">,</span> <span class="s2">&quot;qa_choice&quot;</span><span class="p">)</span>
</code></pre></div></li>
<li>
<p>Confirm the model and adapter loaded successfully</p>
</li>
<li>
<p><strong>Set up the tokenizer</strong></p>
</li>
<li>
<p>Run the tokenizer setup cell:
   <div class="highlight"><pre><span></span><code><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">og</span><span class="o">.</span><span class="n">Tokenizer</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">tokenizer_stream</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">create_stream</span><span class="p">()</span>

<span class="n">search_options</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">search_options</span><span class="p">[</span><span class="s1">&#39;max_length&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">102</span>
<span class="n">search_options</span><span class="p">[</span><span class="s1">&#39;past_present_share_buffer&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">search_options</span><span class="p">[</span><span class="s1">&#39;repeat_penalty&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.1</span>
<span class="n">search_options</span><span class="p">[</span><span class="s1">&#39;temperature&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.7</span>
</code></pre></div></p>
</li>
<li>
<p><strong>Run inference on test questions</strong></p>
</li>
<li>Run the test question cells:
   <div class="highlight"><pre><span></span><code><span class="c1"># Define some test questions</span>
<span class="n">test_questions</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">,</span>
        <span class="s2">&quot;choices&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;A&quot;</span><span class="p">:</span> <span class="s2">&quot;Berlin&quot;</span><span class="p">,</span>
            <span class="s2">&quot;B&quot;</span><span class="p">:</span> <span class="s2">&quot;London&quot;</span><span class="p">,</span>
            <span class="s2">&quot;C&quot;</span><span class="p">:</span> <span class="s2">&quot;Paris&quot;</span><span class="p">,</span>
            <span class="s2">&quot;D&quot;</span><span class="p">:</span> <span class="s2">&quot;Madrid&quot;</span><span class="p">,</span>
            <span class="s2">&quot;E&quot;</span><span class="p">:</span> <span class="s2">&quot;Rome&quot;</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="c1"># ... other questions ...</span>
<span class="p">]</span>

<span class="c1"># Generate responses for each question</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">test_q</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_questions</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Question </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> ---&quot;</span><span class="p">)</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">generate_response</span><span class="p">(</span><span class="n">test_q</span><span class="p">[</span><span class="s2">&quot;question&quot;</span><span class="p">],</span> <span class="n">test_q</span><span class="p">[</span><span class="s2">&quot;choices&quot;</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final answer: </span><span class="si">{</span><span class="n">response</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></li>
<li>
<p>Review the model's answers to see if they're correct</p>
</li>
<li>
<p><strong>Try your own questions</strong></p>
</li>
<li>Run the custom question cell:
   <div class="highlight"><pre><span></span><code><span class="n">ask_question</span><span class="p">(</span>
    <span class="s2">&quot;What is the main purpose of knowledge distillation in machine learning?&quot;</span><span class="p">,</span>
    <span class="p">{</span>
        <span class="s2">&quot;A&quot;</span><span class="p">:</span> <span class="s2">&quot;To make models physically smaller in file size&quot;</span><span class="p">,</span>
        <span class="s2">&quot;B&quot;</span><span class="p">:</span> <span class="s2">&quot;To transfer knowledge from larger models to smaller ones&quot;</span><span class="p">,</span>
        <span class="s2">&quot;C&quot;</span><span class="p">:</span> <span class="s2">&quot;To increase the number of parameters in a model&quot;</span><span class="p">,</span>
        <span class="s2">&quot;D&quot;</span><span class="p">:</span> <span class="s2">&quot;To make training data more compact&quot;</span><span class="p">,</span>
        <span class="s2">&quot;E&quot;</span><span class="p">:</span> <span class="s2">&quot;To replace human knowledge with AI&quot;</span>
    <span class="p">}</span>
<span class="p">)</span>
</code></pre></div></li>
<li>Or modify it to ask your own question</li>
</ol>
<h4 id="key-achievements">Key Achievements:<a class="headerlink" href="#key-achievements" title="Permanent link">&para;</a></h4>
<ul>
<li>Running an ML model entirely on your local machine</li>
<li>Achieving fast inference without cloud resources</li>
<li>Using significantly less memory than the original model</li>
<li>Getting accurate answers to multiple-choice questions</li>
</ul>
<h2 id="what-youve-learned">What You've Learned<a class="headerlink" href="#what-youve-learned" title="Permanent link">&para;</a></h2>
<p>Congratulations! You've successfully completed the Model Distillation Workshop. Here's what you've accomplished:</p>
<ol>
<li><strong>Generated training data</strong> using a large teacher model (DeepSeek-V3)</li>
<li><strong>Fine-tuned a smaller student model</strong> (Phi-4-mini) using LoRA</li>
<li><strong>Optimized the model</strong> with ONNX conversion and int4 quantization </li>
<li><strong>Tested the model</strong> using ONNX Runtime GenAI</li>
<li><strong>Registered the model</strong> to Azure ML</li>
<li><strong>Downloaded and run the model locally</strong></li>
</ol>
<p>You've learned:
- How knowledge distillation transfers intelligence from large to small models
- How to use Microsoft Olive for fine-tuning and optimization
- How to use ONNX Runtime GenAI for efficient inference
- How to deploy models locally for edge computing scenarios</p>
<h2 id="next-steps">Next Steps<a class="headerlink" href="#next-steps" title="Permanent link">&para;</a></h2>
<p>Here are some ways to build on what you've learned:</p>
<ol>
<li><strong>Try different datasets</strong></li>
<li>Use different types of questions or tasks</li>
<li>
<p>Create your own custom dataset</p>
</li>
<li>
<p><strong>Explore different models</strong></p>
</li>
<li>Try different teacher models (GPT-4, Claude, etc.)</li>
<li>
<p>Try different student models (Phi-3, Llama, etc.)</p>
</li>
<li>
<p><strong>Optimize for different targets</strong></p>
</li>
<li>Try different quantization levels (int8, fp16)</li>
<li>
<p>Target different hardware (ARM, NVIDIA Jetson, etc.)</p>
</li>
<li>
<p><strong>Build applications</strong></p>
</li>
<li>Create a simple web UI for your model</li>
<li>
<p>Integrate it with other applications</p>
</li>
<li>
<p><strong>Learn more about:</strong></p>
</li>
<li><a href="https://github.com/microsoft/Olive">Microsoft Olive</a></li>
<li><a href="https://onnxruntime.ai/">ONNX Runtime</a></li>
<li><a href="https://learn.microsoft.com/en-us/azure/machine-learning/">Azure ML</a></li>
</ol>
<p>Thank you for participating in this workshop! Your feedback is valuable for improving future sessions.</p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["navigation.instant", "navigation.footer", "content.code.copy", "navigation.tabs.sticky", "content.tabs.link"], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
        <script src="../js/custom-nav.js"></script>
      
    
  <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>