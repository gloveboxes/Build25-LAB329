# Knowledge Distillation with Azure ML

This notebook (`01.AzureML_Distillation.ipynb`) implements a knowledge distillation pipeline that leverages a teacher model from Azure AI to generate high-quality responses for multiple-choice questions from the commonsense QA dataset.

## Purpose

Knowledge distillation enables transferring knowledge from a large, powerful model (teacher) to a smaller, more efficient model (student). This notebook focuses on the first phase of this process:

1. Loading a dataset from Hugging Face
2. Preparing the data for inferencing
3. Using an Azure AI model as the teacher to generate answers
4. Analyzing the generated responses for quality and bias
5. Saving the resulting data for subsequent student model training

## Workflow Overview

1. **Environment Setup**: Installing required libraries and configuring authentication
2. **Dataset Handling**: Loading and preprocessing the commonsense QA dataset from Hugging Face
3. **Data Preparation**: Formatting questions as chat completions inputs
4. **Teacher Model Inference**: Generating answers using Azure AI Inference API
5. **Results Analysis**: Visualizing answer distributions and potential biases
6. **Data Export**: Saving processed Q&A pairs for student model training

## Technical Components

### Environment Setup
- Installation of essential Python packages:
  - `python-dotenv` for environment variable management
  - `datasets` for Hugging Face dataset access
  - `azure-ai-inference` for connecting to Azure AI services
- Loading environment variables for secure access to Azure AI services

### Dataset Handling
- Uses a custom `CQnAHuggingFaceInputDataset` class to load the "tau/commonsense_qa" dataset
- Implements customizable sample size selection for training, validation, and test data
- Handles dataset splits appropriately based on availability

### Data Preparation
- Creates JSONL format files with standardized message structure
- Implements a specific system prompt instructing the model to respond with A, B, C, D, or E answers
- Formats user prompts with question text and structured answer choices

### Teacher Model Inference
- Connects to Azure AI services using endpoint URL and API key stored in environment variables
- Uses `ChatCompletionsClient` from the Azure AI Inference SDK
- Implements a question processing function with proper error handling
- Displays progress with tqdm for visual feedback during batch processing

### Results Analysis
- Visualizes the distribution of generated answers
- Compares actual vs. expected answer distributions to identify biases
- Analyzes answer patterns by question type and length
- Creates heatmaps to identify potential biases in the teacher model's responses

### Data Export
- Saves processed question-answer pairs in JSONL format
- Extracts and formats only the essential information needed for training

## Code Highlights

### Dataset Loading
```python
train, val, _ = input_dataset.load_hf_dataset(
    dataset_name=dataset_name,
    train_sample_size=train_sample_size,
    val_sample_size=val_sample_size,
    train_split_name="train",
    val_split_name="validation",
)
```

### Azure AI Model Configuration
```python
endpoint = teacher_model_endpoint_url
model_name = teacher_model_name
key = teacher_model_api_key
client = ChatCompletionsClient(endpoint=endpoint, credential=AzureKeyCredential(key))
```

### Question Processing Function
```python
def process_question(question_data):
    try:
        messages = []
        for msg in question_data["messages"]:
            if msg["role"] == "system":
                messages.append(SystemMessage(content=msg["content"]))
            elif msg["role"] == "user":
                messages.append(UserMessage(content=msg["content"]))

        response = client.complete(
            messages=messages,
            model=model_name,
            max_tokens=4000
        )

        return {
            "question": question_data["messages"][1]["content"],
            "response": response.choices[0].message.content,
            "full_response": response
        }
    except Exception as e:
        return {
            "question": question_data["messages"][1]["content"] if len(question_data["messages"]) > 1 else "Error",
            "response": f"Error: {str(e)}",
            "full_response": None
        }
```

## Benefits of This Approach

1. **Quality Data Generation**: Leverages a powerful teacher model to produce high-quality answers
2. **Focused Task Learning**: Structures the input with specific prompts for consistent output format
3. **Bias Detection**: Includes visualizations to identify and understand model biases
4. **Reproducibility**: Structured approach makes the process repeatable with different datasets
5. **Pipeline Integration**: Output format supports seamless integration with subsequent fine-tuning steps

## Next Steps

After generating the distillation dataset with this notebook, the data can be used in subsequent notebooks for:

1. Fine-tuning a smaller student model
2. Converting the model to an optimized format
3. Deploying the student model for inference
4. Evaluating the student model's performance against the teacher

This approach enables knowledge transfer from large, resource-intensive models to more efficient models suitable for deployment in resource-constrained environments while maintaining comparable task performance.
