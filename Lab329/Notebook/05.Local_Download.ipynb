{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9882bf56",
   "metadata": {},
   "source": [
    " Please install Python 3.10+ in your VM Workstation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450d21d1",
   "metadata": {},
   "source": [
    "This notebook needs to run on the local machine so please download the notebooks and execute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39b98db",
   "metadata": {},
   "source": [
    "Login to your azure account az login - device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0057bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all required packages\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package_name):\n",
    "    try:\n",
    "        __import__(package_name)\n",
    "        print(f\"✓ {package_name} is already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package_name}...\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package_name])\n",
    "        print(f\"✓ {package_name} installed successfully\")\n",
    "\n",
    "# Install essential packages\n",
    "install_package('python-dotenv')\n",
    "install_package('azure-identity')\n",
    "install_package('azure-ai-ml')\n",
    "install_package('tqdm')\n",
    "\n",
    "# For safety, ensure azure-ai-ml is latest version\n",
    "print(\"\\nUpdating azure-ai-ml to latest version...\")\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'azure-ai-ml', '--upgrade'])\n",
    "print(\"✓ azure-ai-ml updated to latest version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf11e32",
   "metadata": {},
   "source": [
    "## Library Installation\n",
    "\n",
    "First, let's install all the necessary libraries for model downloading and management. This includes:\n",
    "- `python-dotenv` for environment variables management\n",
    "- `azure-ai-ml` for Azure ML interactions\n",
    "- `tqdm` for progress bars\n",
    "- `azure-identity` for authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8b0a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install azure-ai-ml -U  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2cd670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(\"All packages successfully imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b079049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is no longer needed as imports are handled in the previous cell\n",
    "print(\"Import cell has been consolidated. You can delete this cell if desired.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Azure ML credentials from environment variables\n",
    "subscription_id = os.getenv('AZUREML_SUBSCRIPTION_ID')\n",
    "resource_group = os.getenv('AZUREML_RESOURCE_GROUP')\n",
    "workspace = os.getenv('AZUREML_WS_NAME')\n",
    "\n",
    "# Print values for debugging (remove in production)\n",
    "print(f\"Subscription ID: {subscription_id}\")\n",
    "print(f\"Resource Group: {resource_group}\")\n",
    "print(f\"Workspace: {workspace}\")\n",
    "\n",
    "# Create ML client with the credentials\n",
    "ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd3aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.models.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dba73b",
   "metadata": {},
   "source": [
    "## Download the Fine-Tuned Model\n",
    "\n",
    "Now we'll download the fine-tuned Phi-4-Mini model from Azure ML Model Registry. This process will:\n",
    "\n",
    "1. Connect to Azure ML using our credentials\n",
    "2. Download the ONNX model (int4 quantized for CPU)\n",
    "3. Display a progress bar during download\n",
    "4. Show the download location and model size when complete\n",
    "\n",
    "After downloading, you'll be able to use this model locally for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af58503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model name and version\n",
    "model_name = \"fine-tuning-phi-4-mini-onnx-int4-cpu\"\n",
    "model_version = 1\n",
    "\n",
    "print(f\"\\nStarting download of model: {model_name} (version {model_version})\\n\")\n",
    "\n",
    "# Create a progress bar\n",
    "with tqdm(total=100, desc=\"Downloading model\", unit=\"%\") as pbar:\n",
    "    # Start a background thread to download the model\n",
    "    download_future = ml_client.models.download_async(name=model_name, version=model_version)\n",
    "    \n",
    "    # Monitor the download progress\n",
    "    while not download_future.done():\n",
    "        time.sleep(0.5)\n",
    "        # Update progress bar (approximate since we don't have actual progress info from the API)\n",
    "        pbar.update(1)\n",
    "        pbar.refresh()\n",
    "        if pbar.n >= 95:  # Cap at 95% until confirmed complete\n",
    "            pbar.n = 95\n",
    "            pbar.refresh()\n",
    "\n",
    "    # Get the result\n",
    "    download_path = download_future.result()\n",
    "    pbar.n = 100  # Set to 100% when complete\n",
    "    pbar.refresh()\n",
    "\n",
    "print(f\"\\nModel downloaded successfully to: {download_path}\")\n",
    "\n",
    "# Calculate and display the size of the downloaded model\n",
    "total_size = 0\n",
    "for path, dirs, files in os.walk(download_path):\n",
    "    for f in files:\n",
    "        fp = os.path.join(path, f)\n",
    "        total_size += os.path.getsize(fp)\n",
    "\n",
    "# Convert to appropriate size format (bytes, KB, MB, GB)\n",
    "def format_size(size_bytes):\n",
    "    if size_bytes < 1024:\n",
    "        return f\"{size_bytes} bytes\"\n",
    "    elif size_bytes < 1024**2:\n",
    "        return f\"{size_bytes/1024:.2f} KB\"\n",
    "    elif size_bytes < 102\n",
    "for path, dirs, files in os.walk(download_path):\n",
    "    for f in files:\n",
    "        fp = os.path.join(path, f)\n",
    "        total_size += os.path.getsize(fp)\n",
    "\n",
    "# Convert to appropriate size format (bytes, KB, MB, GB)\n",
    "def format_size(size_bytes):\n",
    "    if size_bytes < 1024:\n",
    "        return f\"{size_bytes} bytes\"\n",
    "    elif size_bytes < 1024**2:\n",
    "        return f\"{size_bytes/1024:.2f} KB\"\n",
    "    elif size_bytes < 1024**3:\n",
    "        return f\"{size_bytes/(1024**2):.2f} MB\"\n",
    "    else:\n",
    "        return f\"{size_bytes/(1024**3):.2f} GB\"\n",
    "\n",
    "print(f\"Total model size: {format_size(total_size)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
