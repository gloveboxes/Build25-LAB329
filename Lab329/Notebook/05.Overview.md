# Local Model Download

This notebook ([05.Local_Download.ipynb](./05.Overview.md)) implements the final phase of our model distillation pipeline: downloading the registered model from Azure Machine Learning to your local environment. This step allows you to use the optimized model in edge devices or other deployment scenarios outside of Azure.

## Purpose

This notebook demonstrates the model download process by:
1. Connecting to an Azure Machine Learning workspace
2. Listing available models in the registry
3. Downloading a specific model version to the local environment
4. Preparing the model for local deployment or edge device implementation

## Workflow Overview

1. **Environment Setup**: Installing necessary packages and importing required libraries
2. **Authentication**: Connecting to Azure ML using the Azure Identity library
3. **Model Discovery**: Listing available models in the Azure ML registry
4. **Model Download**: Retrieving the specific model version for local use

## Technical Components

### Environment Setup
- Installation of required Python packages:
  - `python-dotenv` for environment variable management
  - `azure-ai-ml` for Azure ML SDK functionality
- Importing necessary modules for Azure ML interaction

### Authentication
- Loading authentication details from environment variables
- Using `DefaultAzureCredential` for secure authentication
- Creating an `MLClient` instance to interact with the Azure ML workspace

### Model Discovery
- Querying the Azure ML model registry to list all available models
- Reviewing metadata to identify the target model

### Model Download
- Using the ML client to download the specific model version
- Retrieving the complete model artifacts including the ONNX model and configuration files
- Storing the model locally for edge deployment or offline use

## Code Highlights

```python
# Azure ML setup
from azure.ai.ml import MLClient
from azure.ai.ml.entities import Model
from azure.ai.ml.constants import AssetTypes
from azure.identity import DefaultAzureCredential
import os
from dotenv import load_dotenv

# Authentication
subscription_id = os.getenv('AZUREML_SUBSCRIPTION_ID')
resource_group = os.getenv('AZUREML_RESOURCE_GROUP')
workspace = os.getenv('AZUREML_WS_NAME')

ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace)

# List available models
ml_client.models.list()

# Download specific model
ml_client.models.download("fine-tuning-phi-4-mini-onnx-int4-cpu", 1)
```

## Benefits of This Approach

1. **Offline Capability**: Makes the model available for scenarios without Azure connectivity
2. **Edge Deployment**: Enables deployment to edge devices with limited connectivity
3. **Local Testing**: Facilitates local testing and validation before wider deployment
4. **Flexibility**: Allows integration with non-Azure systems or custom pipelines
5. **Backup**: Provides a local backup of the optimized model

This notebook completes the end-to-end workflow by bringing the optimized model back to the local environment. After downloading the model, you can integrate it with edge devices, custom applications, or other deployment scenarios beyond Azure services. The downloaded model contains all the optimizations applied earlier in the pipeline, including the quantization and format conversion, making it ready for efficient deployment in resource-constrained environments.
